{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1886967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros, ones, expand_dims, asarray\n",
    "from numpy.random import randn, randint\n",
    "from keras.models import Sequential, load_model,Model\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import initializers\n",
    "from keras.initializers import RandomNormal\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1988c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement des données\n",
    "with open('liste_prot', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b324c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test,train\n",
    "X_train,X_test = train_test_split(X_train,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2fea960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 939, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#700 proteines de 939 aa et 21 aa différents\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232f5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(in_shape=(939, 21, 1), size_mini = 10) :\n",
    "    autoencoder = Sequential()\n",
    "    #encoder\n",
    "    autoencoder.add(Input(shape=in_shape))\n",
    "    autoencoder.add(Flatten())\n",
    "    autoencoder.add(Dense(512))\n",
    "    autoencoder.add(LeakyReLU(alpha=0.2))\n",
    "    autoencoder.add(Dropout(0.3))\n",
    "    autoencoder.add(Dense(256))\n",
    "    autoencoder.add(LeakyReLU(alpha=0.2))\n",
    "    autoencoder.add(Dropout(0.3))\n",
    "    autoencoder.add(Dense(size_mini))\n",
    "    #decoder\n",
    "    autoencoder.add(BatchNormalization())\n",
    "    autoencoder.add(Dense(256))\n",
    "    autoencoder.add(LeakyReLU(alpha=0.2))\n",
    "    autoencoder.add(Dense(400))\n",
    "    autoencoder.add(LeakyReLU(alpha=0.2))\n",
    "    autoencoder.add(Dense(512))\n",
    "    autoencoder.add(LeakyReLU(alpha=0.2))\n",
    "    autoencoder.add(Dense(939 * 21 * 1,activation='sigmoid'))\n",
    "    autoencoder.add(Reshape((939, 21, 1)))\n",
    "    autoencoder.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7dc69a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = build_autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "423bb161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 19719)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               10096640  \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10)               40        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               2816      \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 400)               102800    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 400)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               205312    \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 19719)             10115847  \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 939, 21, 1)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,657,353\n",
      "Trainable params: 20,657,333\n",
      "Non-trainable params: 20\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bba93ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 170ms/step - loss: 1.8566 - accuracy: 0.8979 - val_loss: 1.4949 - val_accuracy: 0.9549\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.8263 - accuracy: 0.9516 - val_loss: 1.0665 - val_accuracy: 0.9564\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 0.7560 - accuracy: 0.9584 - val_loss: 0.8857 - val_accuracy: 0.9591\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 3s 155ms/step - loss: 0.7234 - accuracy: 0.9598 - val_loss: 0.7580 - val_accuracy: 0.9610\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 3s 152ms/step - loss: 0.6997 - accuracy: 0.9612 - val_loss: 0.7286 - val_accuracy: 0.9601\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.6777 - accuracy: 0.9616 - val_loss: 0.6812 - val_accuracy: 0.9612\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.6594 - accuracy: 0.9626 - val_loss: 0.6638 - val_accuracy: 0.9625\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 4s 166ms/step - loss: 0.6429 - accuracy: 0.9631 - val_loss: 0.6462 - val_accuracy: 0.9627\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 0.6281 - accuracy: 0.9634 - val_loss: 0.6271 - val_accuracy: 0.9630\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.6123 - accuracy: 0.9644 - val_loss: 0.6133 - val_accuracy: 0.9646\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 4s 165ms/step - loss: 0.5964 - accuracy: 0.9653 - val_loss: 0.5955 - val_accuracy: 0.9653\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.5806 - accuracy: 0.9660 - val_loss: 0.5837 - val_accuracy: 0.9661\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 0.5674 - accuracy: 0.9668 - val_loss: 0.5727 - val_accuracy: 0.9665\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 4s 168ms/step - loss: 0.5535 - accuracy: 0.9675 - val_loss: 0.5574 - val_accuracy: 0.9678\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 4s 164ms/step - loss: 0.5389 - accuracy: 0.9687 - val_loss: 0.5434 - val_accuracy: 0.9689\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 4s 168ms/step - loss: 0.5239 - accuracy: 0.9697 - val_loss: 0.5334 - val_accuracy: 0.9702\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 0.5117 - accuracy: 0.9707 - val_loss: 0.5294 - val_accuracy: 0.9704\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.4995 - accuracy: 0.9717 - val_loss: 0.5123 - val_accuracy: 0.9722\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 3s 155ms/step - loss: 0.4875 - accuracy: 0.9728 - val_loss: 0.5032 - val_accuracy: 0.9729\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.4776 - accuracy: 0.9736 - val_loss: 0.4944 - val_accuracy: 0.9741\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 4s 169ms/step - loss: 0.4672 - accuracy: 0.9746 - val_loss: 0.4847 - val_accuracy: 0.9746\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 4s 173ms/step - loss: 0.4578 - accuracy: 0.9755 - val_loss: 0.4766 - val_accuracy: 0.9756\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 4s 176ms/step - loss: 0.4457 - accuracy: 0.9766 - val_loss: 0.4694 - val_accuracy: 0.9763\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 4s 170ms/step - loss: 0.4375 - accuracy: 0.9772 - val_loss: 0.4631 - val_accuracy: 0.9771\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.4310 - accuracy: 0.9779 - val_loss: 0.4558 - val_accuracy: 0.9777\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 4s 166ms/step - loss: 0.4252 - accuracy: 0.9784 - val_loss: 0.4531 - val_accuracy: 0.9786\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.4174 - accuracy: 0.9790 - val_loss: 0.4496 - val_accuracy: 0.9790\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 4s 166ms/step - loss: 0.4119 - accuracy: 0.9794 - val_loss: 0.4428 - val_accuracy: 0.9786\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 0.4063 - accuracy: 0.9797 - val_loss: 0.4368 - val_accuracy: 0.9792\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.4004 - accuracy: 0.9800 - val_loss: 0.4330 - val_accuracy: 0.9796\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 0.3940 - accuracy: 0.9804 - val_loss: 0.4292 - val_accuracy: 0.9799\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 0.3896 - accuracy: 0.9805 - val_loss: 0.4255 - val_accuracy: 0.9801\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.3859 - accuracy: 0.9806 - val_loss: 0.4226 - val_accuracy: 0.9802\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 0.3816 - accuracy: 0.9808 - val_loss: 0.4216 - val_accuracy: 0.9802\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 0.3776 - accuracy: 0.9811 - val_loss: 0.4160 - val_accuracy: 0.9807\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 3s 151ms/step - loss: 0.3737 - accuracy: 0.9812 - val_loss: 0.4149 - val_accuracy: 0.9808\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 3s 150ms/step - loss: 0.3707 - accuracy: 0.9814 - val_loss: 0.4141 - val_accuracy: 0.9810\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 4s 165ms/step - loss: 0.3664 - accuracy: 0.9816 - val_loss: 0.4089 - val_accuracy: 0.9812\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.3606 - accuracy: 0.9819 - val_loss: 0.4065 - val_accuracy: 0.9813\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 0.3580 - accuracy: 0.9819 - val_loss: 0.4073 - val_accuracy: 0.9816\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 4s 169ms/step - loss: 0.3546 - accuracy: 0.9821 - val_loss: 0.4033 - val_accuracy: 0.9819\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.3510 - accuracy: 0.9823 - val_loss: 0.4011 - val_accuracy: 0.9819\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 0.3467 - accuracy: 0.9825 - val_loss: 0.3977 - val_accuracy: 0.9821\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.3415 - accuracy: 0.9827 - val_loss: 0.3961 - val_accuracy: 0.9821\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.3411 - accuracy: 0.9827 - val_loss: 0.3974 - val_accuracy: 0.9824\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 3s 160ms/step - loss: 0.3389 - accuracy: 0.9828 - val_loss: 0.3981 - val_accuracy: 0.9827\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.3365 - accuracy: 0.9829 - val_loss: 0.3943 - val_accuracy: 0.9829\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 0.3320 - accuracy: 0.9831 - val_loss: 0.3918 - val_accuracy: 0.9826\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.3289 - accuracy: 0.9832 - val_loss: 0.3914 - val_accuracy: 0.9828\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 4s 160ms/step - loss: 0.3257 - accuracy: 0.9833 - val_loss: 0.3900 - val_accuracy: 0.9826\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.3233 - accuracy: 0.9834 - val_loss: 0.3877 - val_accuracy: 0.9831\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 4s 176ms/step - loss: 0.3185 - accuracy: 0.9836 - val_loss: 0.3869 - val_accuracy: 0.9830\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 4s 173ms/step - loss: 0.3182 - accuracy: 0.9836 - val_loss: 0.3877 - val_accuracy: 0.9828\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 4s 164ms/step - loss: 0.3150 - accuracy: 0.9838 - val_loss: 0.3851 - val_accuracy: 0.9830\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 0.3131 - accuracy: 0.9838 - val_loss: 0.3853 - val_accuracy: 0.9834\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 4s 164ms/step - loss: 0.3089 - accuracy: 0.9840 - val_loss: 0.3822 - val_accuracy: 0.9837\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 0.3057 - accuracy: 0.9841 - val_loss: 0.3825 - val_accuracy: 0.9839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "22/22 [==============================] - 3s 152ms/step - loss: 0.3047 - accuracy: 0.9842 - val_loss: 0.3805 - val_accuracy: 0.9831\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.3034 - accuracy: 0.9841 - val_loss: 0.3837 - val_accuracy: 0.9837\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 0.2994 - accuracy: 0.9843 - val_loss: 0.3768 - val_accuracy: 0.9838\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 0.2975 - accuracy: 0.9845 - val_loss: 0.3770 - val_accuracy: 0.9839\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.2951 - accuracy: 0.9845 - val_loss: 0.3772 - val_accuracy: 0.9842\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 0.2928 - accuracy: 0.9846 - val_loss: 0.3749 - val_accuracy: 0.9842\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 3s 152ms/step - loss: 0.2897 - accuracy: 0.9847 - val_loss: 0.3721 - val_accuracy: 0.9840\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 0.2864 - accuracy: 0.9848 - val_loss: 0.3740 - val_accuracy: 0.9839\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.2836 - accuracy: 0.9848 - val_loss: 0.3724 - val_accuracy: 0.9841\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.2818 - accuracy: 0.9849 - val_loss: 0.3737 - val_accuracy: 0.9844\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 0.2798 - accuracy: 0.9850 - val_loss: 0.3731 - val_accuracy: 0.9841\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 0.2801 - accuracy: 0.9850 - val_loss: 0.3746 - val_accuracy: 0.9841\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.2784 - accuracy: 0.9851 - val_loss: 0.3746 - val_accuracy: 0.9841\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 0.2762 - accuracy: 0.9852 - val_loss: 0.3698 - val_accuracy: 0.9844\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.2736 - accuracy: 0.9853 - val_loss: 0.3688 - val_accuracy: 0.9845\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.2697 - accuracy: 0.9854 - val_loss: 0.3694 - val_accuracy: 0.9845\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 0.2686 - accuracy: 0.9855 - val_loss: 0.3719 - val_accuracy: 0.9844\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 4s 166ms/step - loss: 0.2680 - accuracy: 0.9854 - val_loss: 0.3673 - val_accuracy: 0.9847\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 0.2650 - accuracy: 0.9856 - val_loss: 0.3686 - val_accuracy: 0.9847\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.2621 - accuracy: 0.9856 - val_loss: 0.3677 - val_accuracy: 0.9849\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.2606 - accuracy: 0.9857 - val_loss: 0.3686 - val_accuracy: 0.9848\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 0.2612 - accuracy: 0.9856 - val_loss: 0.3671 - val_accuracy: 0.9848\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.2586 - accuracy: 0.9857 - val_loss: 0.3670 - val_accuracy: 0.9849\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.2557 - accuracy: 0.9858 - val_loss: 0.3676 - val_accuracy: 0.9850\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 0.2554 - accuracy: 0.9859 - val_loss: 0.3665 - val_accuracy: 0.9847\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 0.2512 - accuracy: 0.9859 - val_loss: 0.3656 - val_accuracy: 0.9852\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 0.2502 - accuracy: 0.9860 - val_loss: 0.3699 - val_accuracy: 0.9851\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 0.2476 - accuracy: 0.9860 - val_loss: 0.3639 - val_accuracy: 0.9854\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 0.2466 - accuracy: 0.9862 - val_loss: 0.3686 - val_accuracy: 0.9852\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 4s 160ms/step - loss: 0.2441 - accuracy: 0.9861 - val_loss: 0.3670 - val_accuracy: 0.9854\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.2431 - accuracy: 0.9862 - val_loss: 0.3666 - val_accuracy: 0.9854\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 0.2418 - accuracy: 0.9863 - val_loss: 0.3670 - val_accuracy: 0.9850\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.2398 - accuracy: 0.9863 - val_loss: 0.3650 - val_accuracy: 0.9853\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 0.2380 - accuracy: 0.9864 - val_loss: 0.3651 - val_accuracy: 0.9856\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.2357 - accuracy: 0.9864 - val_loss: 0.3652 - val_accuracy: 0.9854\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 0.2356 - accuracy: 0.9864 - val_loss: 0.3653 - val_accuracy: 0.9855\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 3s 155ms/step - loss: 0.2325 - accuracy: 0.9864 - val_loss: 0.3671 - val_accuracy: 0.9856\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.2303 - accuracy: 0.9866 - val_loss: 0.3657 - val_accuracy: 0.9856\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 0.2288 - accuracy: 0.9865 - val_loss: 0.3669 - val_accuracy: 0.9854\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 0.2304 - accuracy: 0.9866 - val_loss: 0.3693 - val_accuracy: 0.9856\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 0.2273 - accuracy: 0.9866 - val_loss: 0.3684 - val_accuracy: 0.9855\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.2247 - accuracy: 0.9867 - val_loss: 0.3668 - val_accuracy: 0.9857\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 0.2244 - accuracy: 0.9868 - val_loss: 0.3671 - val_accuracy: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x213ebec5c10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting même entrée que la sortie\n",
    "autoencoder.fit(X_train,X_train,epochs=100, batch_size=128,validation_data = (X_test,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae8c681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d93133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on récupère le decoder qui correspond aux dernières couches\n",
    "decoder = Sequential()\n",
    "decoder.add(Input(shape=10))\n",
    "for layer in autoencoder.layers[8:]: decoder.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bbc5683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 10)               40        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               2816      \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 400)               102800    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 400)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               205312    \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 19719)             10115847  \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 939, 21, 1)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,426,815\n",
      "Trainable params: 10,426,795\n",
      "Non-trainable params: 20\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c2dbbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on créée une nouvelle protéine\n",
    "test = [[0,1,0,1,0,1,0,1,0,1]]\n",
    "prot = decoder.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd68382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 939, 21, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "971a1ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.66826266],\n",
       "         [0.02801213],\n",
       "         [0.0424239 ],\n",
       "         [0.11522511],\n",
       "         [0.00167561],\n",
       "         [0.05848324],\n",
       "         [0.17943785],\n",
       "         [0.23706606],\n",
       "         [0.0317345 ],\n",
       "         [0.01482689],\n",
       "         [0.17202678],\n",
       "         [0.03613278],\n",
       "         [0.03632024],\n",
       "         [0.01300931],\n",
       "         [0.06885821],\n",
       "         [0.11332825],\n",
       "         [0.07710719],\n",
       "         [0.00740239],\n",
       "         [0.01962546],\n",
       "         [0.00907153],\n",
       "         [0.09047353]]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot[:,85:86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50dd673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_do :\n",
    "#fonction prenant des nombres aléatoires pour la création de nouvelles prot\n",
    "#passer de AE à VAE en rajoutant l'étape de sampling\n",
    "#fonction permettant de passer du tableau en 939*21 à une séquence type \"HWY...\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
